{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f96fba7-fc92-443c-b720-0aa840a4878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from const import MODEL_BASE_PATH\n",
    "from util import get_wandb_runs\n",
    "\n",
    "\n",
    "GROUP_COLS = [\"k\", \"num_rollouts\", \"model_size\"]\n",
    "GPU_TO_TFLOPS_PER_SECOND = {\n",
    "    \"Tesla T4\": 8.141,\n",
    "    \"Tesla L4\": 31.3\n",
    "}\n",
    "GPU_TO_PRICE_PER_SECOND = {\n",
    "    \"Tesla T4\": 0.000164,\n",
    "    \"Tesla L4\": 0.000291\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a2323-d30b-473a-b03a-e7a235a101e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = get_wandb_runs(\"mcts-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a00bcbc-bfa4-4732-bcca-03f4c61bf837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to hold runs data\n",
    "runs_data = []\n",
    "\n",
    "# Extract data from each run\n",
    "for run in runs:\n",
    "    run_data = {\n",
    "        'id': run.id,\n",
    "        'name': run.name,\n",
    "        'state': run.state,\n",
    "        **run.config,\n",
    "        **run.summary._json_dict,\n",
    "    }\n",
    "    run_data = {k: v for k, v in run_data.items() if not k.startswith('_')}\n",
    "    runs_data.append(run_data)\n",
    "\n",
    "\n",
    "runs_df = (\n",
    "    pd.DataFrame(runs_data)\n",
    "    .rename(columns={'elapsed_ms': 'elapsed_seconds'})  # shouldn't be elapsed_ms; i made a mistake...\n",
    "    .assign(\n",
    "        tflops_next_token_gen=lambda x: x['next_token_gen_time'] * x['device_name'].map(GPU_TO_TFLOPS_PER_SECOND),\n",
    "        tflops_seq_gen=lambda x: x['seq_gen_time'] * x['device_name'].map(GPU_TO_TFLOPS_PER_SECOND),\n",
    "        gen_time_perc_of_total=lambda x: (x['seq_gen_time'] + x['next_token_gen_time']) / x['elapsed_seconds'],\n",
    "        model_size=lambda x: x['model_path'].str.extract(r'(\\d+\\.\\d+)B').astype(float)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5937d66-db6e-4d4b-8a03-93a955730272",
   "metadata": {},
   "source": [
    "# how much of total compute time does generation account for?\n",
    "\n",
    "given the plot below, we simply assume that generation time accounts for all inference time.\n",
    "\n",
    "to address this more carefully, we could include CPU performance as well for the remaining time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e2a86e-ce8c-436e-8848-15158f67025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Increase the figure size for better visibility\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the histogram with more bins for granularity\n",
    "sns.histplot(data=runs_df, x=\"gen_time_perc_of_total\", bins=30, color='skyblue', kde=True)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Generation Time Percentage of Total')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Generation Time as Percentage of Total Compute Time')\n",
    "\n",
    "# Stylize\n",
    "sns.set_style('whitegrid')  # Set the style to 'whitegrid' for a clean look\n",
    "\n",
    "# Despine for a cleaner look\n",
    "sns.despine(trim=True)\n",
    "\n",
    "# Finally, display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce6c079-66a3-4ae7-bf9e-3b076cce5906",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregations = {\n",
    "    'tflops_next_token_gen': 'mean',\n",
    "    'tflops_seq_gen': 'mean',\n",
    "    'next_token_gen_time': 'mean',\n",
    "    'seq_gen_time': 'mean',\n",
    "    'train_reward': 'mean',\n",
    "    'test_reward': 'mean',\n",
    "}\n",
    "\n",
    "agg_df = runs_df.groupby(GROUP_COLS).agg(aggregations).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d8bf82-5242-4999-b6f3-ebf1c7167565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "agg_df['model_size'] = agg_df['model_size'].astype('category')\n",
    "\n",
    "# Create a figure with four subplots arranged in a 2x2 grid\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "\n",
    "# Determine the y-axis limits for rewards (Train and Test)\n",
    "max_reward = max(agg_df['train_reward'].max(), agg_df['test_reward'].max())\n",
    "\n",
    "# First plot (Train Reward)\n",
    "sns.barplot(ax=axes[0, 0], data=agg_df, x=\"num_rollouts\", y=\"train_reward\", hue=\"model_size\")\n",
    "axes[0, 0].set_title(\"Mean Train Reward by Number of Rollouts and Model Size\")\n",
    "axes[0, 0].set_xlabel(\"Number of Rollouts\")\n",
    "axes[0, 0].set_ylabel(\"Train Reward\")\n",
    "axes[0, 0].set_ylim(0, max_reward * 1.1)\n",
    "axes[0, 0].legend(title=\"Model Size\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Second plot (Test Reward)\n",
    "sns.barplot(ax=axes[0, 1], data=agg_df, x=\"num_rollouts\", y=\"test_reward\", hue=\"model_size\")\n",
    "axes[0, 1].set_title(\"Mean Test Reward by Number of Rollouts and Model Size\")\n",
    "axes[0, 1].set_xlabel(\"Number of Rollouts\")\n",
    "axes[0, 1].set_ylabel(\"Test Reward\")\n",
    "axes[0, 1].set_ylim(0, max_reward * 1.1)\n",
    "axes[0, 1].legend(title=\"Model Size\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Determine the y-axis limits for generation TFLOPS (Sequence and Next Token)\n",
    "max_tflops = max(agg_df['tflops_next_token_gen'].max(), agg_df['tflops_seq_gen'].max())\n",
    "\n",
    "# Third plot (Sequence Generation TFLOPS)\n",
    "sns.barplot(ax=axes[1, 0], data=agg_df, x=\"num_rollouts\", y=\"tflops_seq_gen\", hue=\"model_size\")\n",
    "axes[1, 0].set_title(\"Mean Sequence Generation TFLOPS per Problem by Number of Rollouts and Model Size\")\n",
    "axes[1, 0].set_xlabel(\"Number of Rollouts\")\n",
    "axes[1, 0].set_ylabel(\"Mean Sequence Generation TFLOPS per Problem\")\n",
    "axes[1, 0].set_ylim(0, max_tflops * 1.1)\n",
    "axes[1, 0].legend(title=\"Model Size\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Fourth plot (Next Token TFLOPS)\n",
    "sns.barplot(ax=axes[1, 1], data=agg_df, x=\"num_rollouts\", y=\"tflops_next_token_gen\", hue=\"model_size\")\n",
    "axes[1, 1].set_title(\"Mean Next Token Generation TFLOPS per Problem by Number of Rollouts and Model Size\")\n",
    "axes[1, 1].set_xlabel(\"Number of Rollouts\")\n",
    "axes[1, 1].set_ylabel(\"Mean Next Token Generation TFLOPS per Problem\")\n",
    "axes[1, 1].set_ylim(0, max_tflops * 1.1)\n",
    "axes[1, 1].legend(title=\"Model Size\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e7f21f-c325-47e4-ac27-ca0018e5a0b5",
   "metadata": {},
   "source": [
    "# fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db74f6-253d-46f7-b168-316e06bf9a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = agg_df[['num_rollouts', 'model_size']]\n",
    "\n",
    "# Model for Mean Sequence Generation TFLOPS\n",
    "y_seq_gen = agg_df['tflops_seq_gen']\n",
    "model_seq_gen = LinearRegression()\n",
    "model_seq_gen.fit(X, y_seq_gen)\n",
    "\n",
    "# Model for Mean Next Token Generation TFLOPS\n",
    "y_next_token_gen = agg_df['tflops_next_token_gen']\n",
    "model_next_token_gen = LinearRegression()\n",
    "model_next_token_gen.fit(X, y_next_token_gen)\n",
    "\n",
    "# Model for Test Reward\n",
    "y_test_reward = agg_df['test_reward']\n",
    "model_test_reward = LinearRegression()\n",
    "model_test_reward.fit(X, y_test_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b1baed-a92b-4aa4-b79b-3b674cc4ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Assuming agg_df and the linear regression models are already defined and fitted\n",
    "\n",
    "# Create a figure with three subplots in one row\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 6))\n",
    "\n",
    "# Plot for Test Reward Model\n",
    "r2_test_reward = r2_score(agg_df['test_reward'], model_test_reward.predict(X))\n",
    "sns.scatterplot(ax=axes[0], x='num_rollouts', y='test_reward', data=agg_df, hue='model_size', style='model_size', s=100)\n",
    "sns.lineplot(ax=axes[0], x='num_rollouts', y=model_test_reward.predict(X), data=agg_df, color='red', label='Fitted Line')\n",
    "axes[0].set_title('Test Reward Model Fit')\n",
    "axes[0].set_xlabel('Number of Rollouts')\n",
    "axes[0].set_ylabel('Test Reward')\n",
    "axes[0].legend(title='Model Size', loc='best')\n",
    "axes[0].text(0.25, 0.05, f'R-squared: {r2_test_reward:.2f}', transform=axes[0].transAxes, horizontalalignment='right') # Annotation\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Plot for Mean Sequence Generation TFLOPS Model\n",
    "r2_seq_gen = r2_score(agg_df['tflops_seq_gen'], model_seq_gen.predict(X))\n",
    "sns.scatterplot(ax=axes[1], x='num_rollouts', y='tflops_seq_gen', data=agg_df, hue='model_size', style='model_size', s=100)\n",
    "sns.lineplot(ax=axes[1], x='num_rollouts', y=model_seq_gen.predict(X), data=agg_df, color='blue', label='Fitted Line')\n",
    "axes[1].set_title('Mean Sequence Generation TFLOPS Model Fit')\n",
    "axes[1].set_xlabel('Number of Rollouts')\n",
    "axes[1].set_ylabel('Mean Sequence Generation TFLOPS')\n",
    "axes[1].legend(title='Model Size', loc='best')\n",
    "axes[1].text(0.25, 0.05, f'R-squared: {r2_seq_gen:.2f}', transform=axes[1].transAxes, horizontalalignment='right') # Annotation\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Plot for Mean Next Token Generation TFLOPS Model\n",
    "r2_next_token_gen = r2_score(agg_df['tflops_next_token_gen'], model_next_token_gen.predict(X))\n",
    "sns.scatterplot(ax=axes[2], x='num_rollouts', y='tflops_next_token_gen', data=agg_df, hue='model_size', style='model_size', s=100)\n",
    "sns.lineplot(ax=axes[2], x='num_rollouts', y=model_next_token_gen.predict(X), data=agg_df, color='green', label='Fitted Line')\n",
    "axes[2].set_title('Mean Next Token Generation TFLOPS Model Fit')\n",
    "axes[2].set_xlabel('Number of Rollouts')\n",
    "axes[2].set_ylabel('Mean Next Token Generation TFLOPS')\n",
    "axes[2].legend(title='Model Size', loc='best')\n",
    "axes[2].text(0.25, 0.05, f'R-squared: {r2_next_token_gen:.2f}', transform=axes[2].transAxes, horizontalalignment='right') # Annotation\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edb2ab4-66fa-4ec3-8b30-618011e2d5b4",
   "metadata": {},
   "source": [
    "# optimization routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed377a1-eed8-4396-a859-2c115e7cbb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_reward_and_tflops(num_rollouts, model_size):\n",
    "    predicted_seq_tflops, = model_seq_gen.predict(pd.DataFrame([[num_rollouts, model_size]], columns=['num_rollouts', 'model_size']))\n",
    "    predicted_next_token_tflops, = model_next_token_gen.predict(pd.DataFrame([[num_rollouts, model_size]], columns=['num_rollouts', 'model_size']))\n",
    "    predicted_tflops = predicted_seq_tflops + predicted_next_token_tflops\n",
    "    predicted_test_reward, = model_test_reward.predict(pd.DataFrame([[num_rollouts, model_size]], columns=['num_rollouts', 'model_size']))\n",
    "    return predicted_test_reward, predicted_tflops\n",
    "\n",
    "\n",
    "def plot_rewards_heatmap(num_rollouts_range, model_sizes, max_tflops_budget):\n",
    "    # Initialize matrices to store the predicted rewards and TFLOPS\n",
    "    reward_matrix = np.zeros((len(num_rollouts_range), len(model_sizes)))\n",
    "    tflops_matrix = np.zeros((len(num_rollouts_range), len(model_sizes)))\n",
    "\n",
    "    # Iterate over combinations and fill the matrices\n",
    "    for i, num_rollouts in enumerate(num_rollouts_range):\n",
    "        for j, model_size in enumerate(model_sizes):\n",
    "            reward_matrix[i, j], tflops_matrix[i, j] = predict_test_reward_and_tflops(num_rollouts, model_size)\n",
    "\n",
    "    # Create a DataFrames\n",
    "    reward_df = pd.DataFrame(reward_matrix, index=num_rollouts_range, columns=np.round(model_sizes, 2))\n",
    "    tflops_df = pd.DataFrame(tflops_matrix, index=num_rollouts_range, columns=np.round(model_sizes, 2))\n",
    "    reward_df.index.name = 'num_rollouts'\n",
    "    tflops_df.index.name = 'num_rollouts'\n",
    "    \n",
    "    # Plot the heatmap for rewards\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    sns.heatmap(reward_df, annot=True, fmt=\".4f\", cmap=\"viridis\", cbar_kws={'label': 'Predicted Reward'})\n",
    "    plt.title(f'Heatmap of Predicted Reward (Missing cells indicate total TFLOPS > Budget ({max_tflops_budget} TFLOPS)')\n",
    "    plt.xlabel('Model Size')\n",
    "    plt.ylabel('Number of Rollouts')\n",
    "    plt.show()\n",
    "\n",
    "    # Return DataFrames\n",
    "    return reward_df, tflops_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a295d-f99e-4a9d-897b-6f75ebcef867",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TFLOPS_BUDGET = 3e3\n",
    "NUM_ROLLOUTS_RANGE = range(2, 6)\n",
    "MODEL_SIZES = np.linspace(1.5, 3.0, 16)\n",
    "\n",
    "\n",
    "reward_df, tflops_df = plot_rewards_heatmap(NUM_ROLLOUTS_RANGE, MODEL_SIZES, MAX_TFLOPS_BUDGET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68ddd89-cec3-4faf-bb55-47c8c8a0c1c1",
   "metadata": {},
   "source": [
    "# aggregate predicted cost data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92570b25-2c60-4013-b2d7-6cbfd13531b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflops_df_melted = tflops_df.reset_index().melt(id_vars='num_rollouts', var_name='model_size', value_name='predicted_tflops')\n",
    "reward_df_melted = reward_df.reset_index().melt(id_vars='num_rollouts', var_name='model_size', value_name='predicted_test_reward')\n",
    "pred_df = tflops_df_melted.merge(reward_df_melted, on=['num_rollouts', 'model_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e73ae60-90ba-4f40-96d3-29a5c676b828",
   "metadata": {},
   "source": [
    "# compute costs in time and $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf58025e-9995-43bd-84c3-06ea81f14c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_problems = len(set(runs_df['problem_index']))\n",
    "data = []\n",
    "\n",
    "for idx, row in pred_df.iterrows():\n",
    "    for gpu, tflops_per_second in GPU_TO_TFLOPS_PER_SECOND.items():\n",
    "        d = row.to_dict()\n",
    "        d['predicted_time'] = num_problems * d['predicted_tflops'] / tflops_per_second\n",
    "        d['predicted_dollar_cost'] = d['predicted_time'] * GPU_TO_PRICE_PER_SECOND[gpu]\n",
    "        d['predicted_time_minutes'] = d['predicted_time'] / 60\n",
    "        d['gpu'] = gpu\n",
    "        data.append(d)\n",
    "\n",
    "\n",
    "costs_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233756b7-af22-48b1-a6c8-a445a2a37713",
   "metadata": {},
   "outputs": [],
   "source": [
    "costs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3551177b-1a02-4ea2-bb14-bbd79128705e",
   "metadata": {},
   "source": [
    "# choose setting based on budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7448275-f5e7-4a35-a75e-f0f41340cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample DataFrame setup (Replace this with your actual DataFrame)\n",
    "# costs_df = pd.read_csv('path_to_your_csv.csv')  # Load your DataFrame from a CSV file\n",
    "\n",
    "# Define the grid range for dollar cost and time\n",
    "dollar_cost_min, dollar_cost_max = costs_df['predicted_dollar_cost'].min(), costs_df['predicted_dollar_cost'].max()\n",
    "time_minutes_min, time_minutes_max = costs_df['predicted_time_minutes'].min(), costs_df['predicted_time_minutes'].max()\n",
    "\n",
    "# Define the number of points in the grid for both dimensions\n",
    "num_points = 10  # for example, you can increase this for a finer grid\n",
    "\n",
    "# Create the grid\n",
    "dollar_cost_grid = np.linspace(dollar_cost_min, dollar_cost_max, num_points)\n",
    "time_minutes_grid = np.linspace(time_minutes_min, time_minutes_max, num_points)\n",
    "\n",
    "# Initialize the list to store the best configurations\n",
    "best_configs = []\n",
    "\n",
    "# Iterate over the grid\n",
    "for dollar_cost in dollar_cost_grid:\n",
    "    for time_minutes in time_minutes_grid:\n",
    "        # Filter rows that meet the current constraints\n",
    "        filtered_df = costs_df[(costs_df['predicted_dollar_cost'] <= dollar_cost) &\n",
    "                               (costs_df['predicted_time_minutes'] <= time_minutes)]\n",
    "        \n",
    "        # If there are any rows that meet the condition, select the one with the highest predicted_test_reward\n",
    "        if not filtered_df.empty:\n",
    "            best_row = filtered_df.loc[filtered_df['predicted_test_reward'].idxmax()]\n",
    "            best_configs.append({\n",
    "                'dollar_cost': dollar_cost,\n",
    "                'time_minutes': time_minutes,\n",
    "                'predicted_test_reward': best_row['predicted_test_reward'],\n",
    "                'gpu': best_row['gpu'],\n",
    "                'num_rollouts': best_row['num_rollouts'],\n",
    "                'model_size': best_row['model_size']\n",
    "            })\n",
    "\n",
    "# Convert the best configurations to a DataFrame\n",
    "best_configs_df = pd.DataFrame(best_configs)\n",
    "\n",
    "# Pivot 'best_configs_df'\n",
    "heatmap_test_reward = best_configs_df.pivot(index='dollar_cost', columns='time_minutes', values='predicted_test_reward')\n",
    "heatmap_num_rollouts = best_configs_df.pivot(index='dollar_cost', columns='time_minutes', values='num_rollouts')\n",
    "heatmap_model_size = best_configs_df.pivot(index='dollar_cost', columns='time_minutes', values='model_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27bcf63-5f5e-4dbf-9e36-986c3e928aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 8))\n",
    "cmap = sns.light_palette(\"orange\")\n",
    "ax = sns.heatmap(heatmap_test_reward, annot=False, fmt=\".2f\", cmap=cmap, cbar_kws={'label': 'Predicted Test Reward'})\n",
    "\n",
    "# Annotate each cell with the combined information\n",
    "for i, row in enumerate(heatmap_test_reward.values):\n",
    "    for j, val in enumerate(row):\n",
    "        gpu = heatmap_gpus.iloc[i, j]\n",
    "        num_rollouts = heatmap_num_rollouts.iloc[i, j]\n",
    "        model_size = heatmap_model_size.iloc[i, j]\n",
    "        reward_val = val if pd.notnull(val) else 0\n",
    "        text = f\"{reward_val:.4f}\\n{gpu}, ({num_rollouts}, {model_size})\"\n",
    "        ax.text(j + 0.5, i + 0.5, text, ha='center', va='center', fontsize=9)\n",
    "\n",
    "plt.title('Heatmap of Predicted Test Reward\\nAnnotated with: GPU, (num_rollouts, model_size)')\n",
    "plt.xlabel('Time Minutes Budget')\n",
    "plt.ylabel('Dollar Cost Budget')\n",
    "\n",
    "# Round the tick labels to 3 significant digits\n",
    "ax.set_xticklabels(['{:.3g}'.format(float(t.get_text())) for t in ax.get_xticklabels()])\n",
    "ax.set_yticklabels(['{:.3g}'.format(float(t.get_text())) for t in ax.get_yticklabels()])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
